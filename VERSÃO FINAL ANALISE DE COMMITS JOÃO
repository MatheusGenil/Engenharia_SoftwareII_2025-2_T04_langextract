from transformers import pipeline
import os
import re
import subprocess

class HuggingFaceWrapper:
    def __init__(self, model_name: str):
        self.pipeline = pipeline("zero-shot-classification", model=model_name)

    def classify_text(self, text: str, candidate_labels: list[str]):
        return self.pipeline(text, candidate_labels=candidate_labels)

# ======================================================
# üîπ CONFIGURA√á√ïES
# ======================================================

# Reposit√≥rio alvo
repo_url = "https://github.com/google/langextract.git"

# Pasta tempor√°ria onde o reposit√≥rio ser√° clonado
repo_dir = "repo_temp"

# ======================================================
# üîπ CLONAGEM DO REPOSIT√ìRIO
# ======================================================
if not os.path.exists(repo_dir):
    print(f"üì• Clonando reposit√≥rio {repo_url} ...")
    subprocess.run(["git", "clone", repo_url, repo_dir], check=True)
else:
    print(f"‚úÖ Reposit√≥rio j√° clonado em {repo_dir}")

# ======================================================
# üîπ EXTRA√á√ÉO DOS COMMITS RELEVANTES
# ======================================================

# Termos de busca (como no seu c√≥digo 2)
termos_busca = [
    "architecture", "architectural", "pattern", "design",
    "registry", "factory", "refactor", "provider", "module"
]

padrao_grep = "|".join(termos_busca)

# Executa comando git log e filtra mensagens de commit
print("üîé Coletando commits relevantes ...")

result = subprocess.run(
    ["git", "-C", repo_dir, "log", "--all", "-i", "-E", f"--grep={padrao_grep}", "--pretty=format:%s"],
    capture_output=True,
    text=True
)

commits_filtrados = result.stdout.strip()

if not commits_filtrados:
    print("‚ö†Ô∏è Nenhum commit relevante encontrado.")
else:
    linhas_relevantes = commits_filtrados.splitlines()
    print(f"‚úÖ {len(linhas_relevantes)} mensagens de commit relevantes extra√≠das.\n")

# ======================================================
# üîπ PREPARA√á√ÉO DO TEXTO PARA AN√ÅLISE
# ======================================================
texto_filtrado = "\n".join(linhas_relevantes) if commits_filtrados else ""

if not texto_filtrado.strip():
    print("‚ö†Ô∏è Nenhum texto relevante encontrado nos commits.")
else:
    print("üß† Analisando mensagens de commit com modelo zero-shot ...")

# ======================================================
# üîπ DEFINI√á√ÉO DAS ARQUITETURAS
# ======================================================
candidate_labels = [
    "Monolithic",
    "Microservices",
    "Serverless",
    "Event Driven",
    "Layered",
    "Hexagonal",
    "Clean Architecture",
    "Service Oriented Architecture",
    "Client Server",
    "MVC",
    "Singleton",
    "Factory Method",
    "Observer",
    "Strategy",
    "Adapter",
    "Facade",
    "Decorator",
    "Repository",
    "Command",
    "Dependency Injection",
    "Modular",
    "Pipe and Filter",
    "Provider-based Architecture",
    "Plugin-based Architecture"
]

# ======================================================
# üîπ CLASSIFICA√á√ÉO VIA HUGGINGFACE
# ======================================================
model_name = "facebook/bart-large-mnli"
hf = HuggingFaceWrapper(model_name)

texto_para_analisar = texto_filtrado or "No commit data found."
result = hf.classify_text(texto_para_analisar, candidate_labels)

# ======================================================
# üîπ RESULTADOS
# ======================================================
print("\n============== " + model_name + " ==============")
print("\nüèóÔ∏è  Resultado da infer√™ncia de arquitetura (baseada nos commits):")
for label, score in zip(result["labels"], result["scores"]):
    print(f"{label}: {score:.2%}")

print(f"\n‚û°Ô∏è  Arquitetura mais prov√°vel: {result['labels'][0]} (confian√ßa: {result['scores'][0]:.2%})")
