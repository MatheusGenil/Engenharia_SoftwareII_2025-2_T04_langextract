from transformers import pipeline
import requests

class HuggingFaceWrapper:
    def __init__(self, model_name: str):
        self.pipeline = pipeline("zero-shot-classification", model=model_name)
    
    def classify_text(self, text: str, candidate_labels: list[str]):
        return self.pipeline(text, candidate_labels=candidate_labels)

# URL do README do projeto langextract
url = "https://github.com/google/langextract/blob/main/README.md"
readme_text = requests.get(url).text

# Candidatas de arquitetura
candidate_labels = ["MVC", "Layered", "Microservices", "Event Driven", "Pipe and Filter", "Factory", "Provider"]

# Modelo compat√≠vel com o pipeline zero-shot-classification
model_name = "MoritzLaurer/deberta-v3-large-zeroshot-v1"
hf = HuggingFaceWrapper(model_name)

result = hf.classify_text(readme_text, candidate_labels)

print("\n============== " + model_name + " ==============")
print("\nüèóÔ∏è  Resultado da infer√™ncia de arquitetura:")
for label, score in zip(result["labels"], result["scores"]):
    print(f"{label}: {score:.2%}")

print(f"\n‚û°Ô∏è  Arquitetura mais prov√°vel: {result['labels'][0]} (confian√ßa: {result['scores'][0]:.2%})")
