{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "gpuType": "T4",
      "provenance": []
    },
    "accelerator": "GPU",
    "kaggle": {
      "accelerator": "gpu"
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -U Transformers"
      ],
      "metadata": {
        "id": "q-jUQHO6iBQF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fb942a5-824b-4491-93ef-632fa1e78536"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from Transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from Transformers) (0.36.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from Transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from Transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from Transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from Transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from Transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from Transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from Transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from Transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->Transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->Transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->Transformers) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->Transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->Transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->Transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->Transformers) (2025.10.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Local Inference on GPU\n",
        "Model page: https://huggingface.co/deepset/xlm-roberta-large-squad2\n",
        "\n",
        "âš ï¸ If the generated code snippets do not work, please open an issue on either the [model repo](https://huggingface.co/deepset/xlm-roberta-large-squad2)\n",
        "\t\t\tand/or on [huggingface.js](https://github.com/huggingface/huggingface.js/blob/main/packages/tasks/src/model-libraries-snippets.ts) ðŸ™"
      ],
      "metadata": {
        "id": "z7tY9dlaiBQG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use a pipeline as a high-level helper\n",
        "from transformers import pipeline\n",
        "\n",
        "pipe = pipeline(\"question-answering\", model=\"deepset/roberta-large-squad2\")"
      ],
      "metadata": {
        "id": "Ds3yZBrliBQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "lSyuxFVmjCC2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/google/langextract.git"
      ],
      "metadata": {
        "id": "Yy2cbXYTiT5p",
        "outputId": "ee129bc1-66b6-4c34-f7eb-b0326bf1b057",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'langextract'...\n",
            "remote: Enumerating objects: 1426, done.\u001b[K\n",
            "remote: Counting objects: 100% (910/910), done.\u001b[K\n",
            "remote: Compressing objects: 100% (399/399), done.\u001b[K\n",
            "remote: Total 1426 (delta 714), reused 514 (delta 511), pack-reused 516 (from 3)\u001b[K\n",
            "Receiving objects: 100% (1426/1426), 10.50 MiB | 21.86 MiB/s, done.\n",
            "Resolving deltas: 100% (927/927), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Entrando na pasta\n",
        "os.chdir('langextract')"
      ],
      "metadata": {
        "id": "td8kXg6Ziv4k"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "termos_busca = \"architecture|pattern|registry|factory|refactor|design\""
      ],
      "metadata": {
        "id": "ULpH3bkBl-bU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Git, pesquise em todos os branches, ignorando maiÃºsculas/minÃºsculas, e encontre apenas os commits cujos tÃ­tulos mencionem 'architecture' ou 'pattern' ou 'registry' (ou os outros termos).\n",
        "#Pegue sÃ³ os tÃ­tulos desses commits e salve essa lista filtrada no arquivo commits_filtrados.txt.\n",
        "!git log --all -i -E --grep=\"{termos_busca}\" --pretty=format:\"%s\" > ../commits_filtrados.txt"
      ],
      "metadata": {
        "id": "0K_V1ANjmJc_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#listando os commits e salvando sÃ³ o titulo no arquivo commits\n",
        "#!git log --pretty=format:\"%s\" > ../commits.txt"
      ],
      "metadata": {
        "id": "cM_5H_kbjISX"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Voltando para o diretÃ³rio anterior\n",
        "os.chdir('..')"
      ],
      "metadata": {
        "id": "KqWaCgfGj2sn"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "iB0wHER6kxJ0",
        "outputId": "50a24715-747d-457f-cb20-324868f30c9c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "commits_filtrados.txt  langextract  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"commits_filtrados.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "        context_filtrado = f.read()"
      ],
      "metadata": {
        "id": "XN6Koc2BnKcB"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ðŸ”¹ Perguntas otimizadas\n",
        "questions = [\n",
        "    \"What architecture was the codebase refactored into?\",\n",
        "    \"Into what architecture was the codebase refactored?\",\n",
        "    \"What software architecture did the codebase adopt after refactoring?\",\n",
        "    \"Which software architecture was applied during the refactor?\",\n",
        "    \"What architecture style was implemented in the codebase?\",\n",
        "    \"Which architectural pattern was implemented?\",\n",
        "    \"What architecture pattern was introduced in the project?\",\n",
        "    \"Which architecture pattern does the codebase follow after the refactor?\",\n",
        "    \"What kind of software architecture does the codebase use?\",\n",
        "    \"Which architecture framework or pattern was adopted?\",\n",
        "]\n",
        "\n",
        "# ðŸ”¹ Avalia todas e seleciona a mais confiÃ¡vel\n",
        "melhor = {\"question\": None, \"answer\": None, \"score\": 0}\n",
        "\n",
        "for q in questions:\n",
        "    result = pipe(question=q, context=context_filtrado)\n",
        "    print(f\"\\nPergunta: {q}\")\n",
        "    print(f\"â†’ Resposta: {result['answer']}\")\n",
        "    print(f\"â†’ ConfianÃ§a: {result['score']:.4f}\")\n",
        "\n",
        "    if result[\"score\"] > melhor[\"score\"]:\n",
        "        melhor = {\"question\": q, \"answer\": result[\"answer\"], \"score\": result[\"score\"]}\n",
        "\n",
        "# ðŸ”¹ Resultado final\n",
        "print(\"\\n=== MELHOR RESULTADO ===\")\n",
        "print(f\"Pergunta: {melhor['question']}\")\n",
        "print(f\"Resposta: {melhor['answer']}\")\n",
        "print(f\"ConfianÃ§a: {melhor['score']:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VdAhByEW6vN",
        "outputId": "81a66c05-7086-4240-de4e-3a0e27bfce7c"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Pergunta: What architecture was the codebase refactored into?\n",
            "â†’ Resposta: clean layered\n",
            "â†’ ConfianÃ§a: 0.9504\n",
            "\n",
            "Pergunta: Into what architecture was the codebase refactored?\n",
            "â†’ Resposta: clean layered\n",
            "â†’ ConfianÃ§a: 1.0264\n",
            "\n",
            "Pergunta: What software architecture did the codebase adopt after refactoring?\n",
            "â†’ Resposta: clean layered architecture\n",
            "â†’ ConfianÃ§a: 0.8975\n",
            "\n",
            "Pergunta: Which software architecture was applied during the refactor?\n",
            "â†’ Resposta: clean layered architecture\n",
            "â†’ ConfianÃ§a: 0.1456\n",
            "\n",
            "Pergunta: What architecture style was implemented in the codebase?\n",
            "â†’ Resposta: clean layered architecture\n",
            "â†’ ConfianÃ§a: 0.5889\n",
            "\n",
            "Pergunta: Which architectural pattern was implemented?\n",
            "â†’ Resposta: clean layered architecture\n",
            "â†’ ConfianÃ§a: 0.0001\n",
            "\n",
            "Pergunta: What architecture pattern was introduced in the project?\n",
            "â†’ Resposta: clean layered architecture\n",
            "â†’ ConfianÃ§a: 0.0728\n",
            "\n",
            "Pergunta: Which architecture pattern does the codebase follow after the refactor?\n",
            "â†’ Resposta: clean layered\n",
            "â†’ ConfianÃ§a: 0.5556\n",
            "\n",
            "Pergunta: What kind of software architecture does the codebase use?\n",
            "â†’ Resposta: clean layered architecture\n",
            "â†’ ConfianÃ§a: 0.2713\n",
            "\n",
            "Pergunta: Which architecture framework or pattern was adopted?\n",
            "â†’ Resposta: clean layered architecture\n",
            "â†’ ConfianÃ§a: 0.0000\n",
            "\n",
            "=== MELHOR RESULTADO ===\n",
            "Pergunta: Into what architecture was the codebase refactored?\n",
            "Resposta: clean layered\n",
            "ConfianÃ§a: 1.0264\n"
          ]
        }
      ]
    }
  ]
}